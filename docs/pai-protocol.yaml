version: String, required # Protocol version, current version is 2
name: String, required
type: String, required # The type of the component. Must be one of the following: job, data, script, dockerimage, or output
tag: String, optional # Component tag. Default is latest
contributor: String, optional
description: String, optional
license: String, optional

prerequisites: # Optional
  - version: String, optional # If omitted, follow the version in root
    name: String, required
    type: String, required # Component type. Must be one of the following: data, script, dockerimage, or output. Prerequisites.type cannot be "job"
    tag: String, optional # Component tag. Default is latest
    auth: Object, optional # Only available when the type is dockerimage
      credential: String, optional # "username:password" encoded in base64
      registryuri: String, optional
    uri: String or list, required # Only when the type is data can the uri be a list

parameters: # Optional, can be omitted
  <param1>: value1Type # Specify name and value of all the referencable parameters that will be used in the whole job template. They can be referenced by $$paramName$$.
  <param2>: value2Type

jobRetryCount: Integer, optional # Default is 0
taskRoles:
  - version: String, optional # Protocol version, default is 2
    name: String, required  # Name of the taskRole
    instances: Integer, optional # Default is 1, instances of a taskRole
    completion:
      minFailedInstances: Integer or null, optional # Default 1
      minSucceededInstances: Integer or null, optional # Default null
    taskRetryCount: Integer, optional # Default is 0
    dockerImage: String, required # Should reference to a dockerimage defined in prerequisites
    data: String, optional # Should reference to data defined in prerequisites
    output: String, optional # Should reference to output defined in prerequisites
    script: String, optional # Should reference to script defined in prerequisites
    extraContainerOptions: 
      shmMB: Integer, optional # config the /dev/shm in a docker container, https://docs.docker.com/compose/compose-file/#shm_size
    resourcePerInstance:
      cpu: Integer, required
      memoryMB: Integer, required
      gpu: Integer, required
      ports:
        <portLabel1>: Integer, optional, default is 0 # Only for host network
    commands:
      - String, required
    # to handle that a component may interact with different component differently, user is encouraged to place the codes handling such difference in the "deployments" field.
    # e.g., a job may get input data through wget, hdfc -dfs cp, copy, or just directly read from remote storage. This logic can be placed here.
    # in summary, the deployments field is responsible to make sure the job to run properly in a deployment specific runtime environment.
    # one could have many deployments, but only the first deployment can be activated at runtime. User can choose the deployment at job submission time.
    deployments: # Optional
      preCommands:
        - String, optional # execute before $$commands$$
      postCommands:
        - String, optional # execute after $$commands$$


attachments: # optional, cluster specific parameters
  - version: String, optional
    virtualCluster: String, optional


# Below is an example for distributed tensorflow:

version: 2
name: tensorflow_cifar10
type: job
tag: 1.0.0
contributor: Alice
description: image classification, cifar10 dataset, tensorflow, distributed training
license: CC BY-NC-SA

prerequisites:
  - version: 2
    name: tf_example
    type: dockerimage
    tag: latest
    auth:
      # "username:password" encoded in base64, e.g.
      # openssl enc -base64 <<< "81f1fd6a-2844-4072-982d-62371fa37bd3:user1"
      credential: ODFmMWZkNmEtMjg0NC00MDcyLTk4MmQtNjIzNzFmYTM3YmQzOnVzZXIx
      registryuri: openpai.azurecr.io
    uri: openpai/pai.example.tensorflow
  - version: 2
    name: tensorflow_cifar10_model
    type: output
    tag: latest
    uri: hdfs://10.151.40.179:9000/core/cifar10_model
  - version: 2
    name: tensorflow_cnnbenchmarks
    type: script
    tag: 84820935288cab696c9c2ac409cbd46a1f24723d
    uri: https://github.com/MaggieQi/benchmarks
  - version: 2
    name: cifar10
    type: data
    tag: latest
    uri:
      - https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz

parameters:
  model: resnet20
  batchsize: 32

jobRetryCount: 1
taskRoles:
  - version: 2
    name: worker
    instance: 1
    completion:
      minFailedInstances: 1
      minSucceededInstances: 1
    taskRetryCount: 0
    dockerImage: tf_example
    data: cifar10
    output: tensorflow_cifar10_model
    script: tensorflow_cnnbenchmarks
    extraContainerOptions: 
      shmMB: 64      
    resourcePerInstance:
      cpu: 2
      memoryMB: 16384
      gpu: 4
      ports: { ssh: 0, http: 0 }
    commands:
      - cd script_$$taskRoles.worker.script.tf_cnnbenchmarks.name$$/scripts/tf_cnn_benchmarks
      - >
        python tf_cnn_benchmarks.py --job_name=worker --local_parameter_device=gpu --variable_update=parameter_server
        --ps_hosts=$PAI_TASK_ROLE_ps_server_HOST_LIST --worker_hosts=$PAI_TASK_ROLE_worker_HOST_LIST
        --task_index=$PAI_CURRENT_TASK_ROLE_CURRENT_TASK_INDEX --model=$$parameters.model$$ --batch_size=$$parameters.batchsize$$
        --data_dir=$PAI_WORK_DIR/data_$$taskRoles.worker.data.cifar10.name$$ --data_name=$$taskRoles.worker.data.cifar10.name$$
        --train_dir=$PAI_WORK_DIR/output_$$taskRoles.worker.output.tf_cifar10_model.name$$
    deployments:
      preCommands:
        - wget $$taskRoles.worker.data.cifar10.uri$$ -P data_$$taskRoles.worker.data.cifar10.name$$ # if local data cache deployed, one can copy data from local cache, only wget in case of cache miss
        - >
          git clone $tasks.worker.script.tensorflow_cnnbenchmarks.uri$$ script_$$tasks.worker.script.tf_cnnbenchmarks.name$$ &&
          cd script_$$taskRoles.worker.script.tf_cnnbenchmarks.name$$ &&
          git checkout $$taskRoles.worker.script.tf_cnnbenchmarks.tag$$ && cd ..
          # and the system will go ahead to execute $$taskRoles.worker.commands$$

  - version: 2
    name: ps_server
    instances: 1
    completion:
      minFailedInstances: 1
      minSucceededInstances: null
    taskRetryCount: 0
    dockerImage: tf_example
    data: cifar10
    output: tensorflow_cifar10_model
    script: tensorflow_cnnbenchmarks
    extraContainerOptions: 
      shmMB: 64
    resourcePerInstanec:
      cpu: 2
      memoryMB: 8192
      gpu: 0
      ports: { ssh: 0, http: 0 }
    commands:
      - cd script_$$taskRoles.ps_server.script.tf_cnnbenchmarks.name$$/scripts/tf_cnn_benchmarks
      - >
        python tf_cnn_benchmarks.py --job_name=ps --local_parameter_device=gpu --variable_update=parameter_server
        --ps_hosts=$PAI_TASK_ROLE_ps_server_HOST_LIST --worker_hosts=$PAI_TASK_ROLE_worker_HOST_LIST
        --task_index=$PAI_CURRENT_TASK_ROLE_CURRENT_TASK_INDEX --model=$$parameters.model$$ --batch_size=$$parameters.batchsize$$
        --data_dir=$PAI_WORK_DIR/data_$$taskRoles.ps_server.data.cifar10.name$$ --data_name=$$taskRoles.ps_server.data.cifar10.name$$
        --train_dir=$PAI_WORK_DIR/output_$$taskRoles.ps_server.output.tf_cifar10_model.name$$
    deployments:
      preCommands:
        - wget $$taskRoles.ps_server.data.cifar10.uri$$ -P data_$$taskRoles.ps_server.data.cifar10.name$$
        - >
          git clone $tasks.ps_server.script.tensorflow_cnnbenchmarks.uri$$ script_$$tasks.ps_server.script.tf_cnnbenchmarks.name$$ &&
          cd script_$$taskRoles.ps_server.script.tf_cnnbenchmarks.name$$ &&
          git checkout $$taskRoles.ps_server.script.tf_cnnbenchmarks.tag$$ && cd ..
          # and the system will go ahead to execute $$taskRoles.ps_server.commands$$
      postCommands:
        # after the execution of $$taskRoles.ps_server.commands$$, the system goes here
        - hdfs dfs -cp output_$$taskRoles.ps_server.output.tf_cifar10_model.name$$ $$taskRoles.ps_server.output.tf_cifar10_model.uri$$
        # assume the model is output locally, and this command copies the local output to hdfs. One can output to hdfs directly.
        # In this case, you will have to change "--train_dir=$PAI_WORK_DIR/output_$$taskRoles.ps_server.output.tf_cifar10_model.name$$"
